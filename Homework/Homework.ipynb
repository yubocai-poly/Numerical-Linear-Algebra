{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sticky-painting",
   "metadata": {},
   "source": [
    "# Homework:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bf023e2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**NAME: Yubo Cai**\n",
    "\n",
    "**User ID: yubuo.cai@polytechinique**\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions:** \n",
    "- The clarity (clean writing) and the organization of the work (numbering the questions appropriately) are taken into account during the correction. \n",
    "- Before uploading your notebook, **Kernel/restart and clear output**. And **verify that your code is running cell after cell.**\n",
    "- This homework is **optional**. It counts at most as 4 **bonus** points on the final grade (over 20) of the course (capped at 20). It must be uploaded back on moodle **BEFORE** the 12th of March at 8PM (Paris time) to be counted, no delay will be accepted. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f549ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages:\n",
    "\n",
    "# this package allows to work efficiently with arrays\n",
    "import numpy as np\n",
    "# this package is used to draw graphs\n",
    "import matplotlib.pyplot as plt\n",
    "# for the numerical application in the end, we will use pi\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d6f65d",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64429d69",
   "metadata": {},
   "source": [
    "Consider the matrices \n",
    "\n",
    "$$A = \\left(\\begin{array}{ccc} 1 & 0 & 0 \\\\ 2 & 3 & 0 \\\\ 4 & 5 & 6\\end{array}\\right), \\qquad \n",
    "  B = \\left(\\begin{array}{ccc} 1 & 2 & 1 \\\\ 2 & 5 & 4 \\\\ 1 & 4 & 6\\end{array}\\right), $$\n",
    "and the vector $b = \\left(\\begin{array}{c} 1 \\\\ 1 \\\\ 1\\end{array}\\right)$.\n",
    "\n",
    "**Question 1.1.**\n",
    "\n",
    "Write down the steps of the forward substitution algorithm to solve the problem $AV = b$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab66c108",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n",
    "Since the matrix $A$ is already in the lower triangular form and therefore invertible. Also, the values in diagonal are nonzero. So we can directly apply the forward substitution algorithm with the following algorithms:\n",
    "\n",
    "- Interations: For $i$ from 1 to $N$ (here N is 3)\n",
    "\n",
    "  $$\n",
    "  V_{i} = \\frac{b_{i}-\\sum_{j-1}^{i-1}A_{i,j}V_{j}}{A_{i,i}}\n",
    "  $$\n",
    "\n",
    "Therefore, we have the following program to solve the problem $AV = b$, we have the final result:\n",
    "$$\n",
    "V= \\begin{pmatrix} 1 \\\\ -\\frac{1}{3} \\\\ -\\frac{2}{9} \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40491cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_substitution(L, b):\n",
    "    V = np.ones(len(b))\n",
    "    N = len(b)\n",
    "    for i in range(1, N + 1):\n",
    "        V[i - 1] = (b[i - 1] -\n",
    "                    np.dot(L[i - 1, 0:i - 1], V[0:i - 1])) / L[i - 1, i - 1]\n",
    "\n",
    "    return V\n",
    "\n",
    "\n",
    "# result\n",
    "L = np.array([[1, 0, 0], [2, 3, 0], [4, 5, 6]])\n",
    "b1 = np.array([1, 1, 1])\n",
    "\n",
    "sol1 = forward_substitution(L, b1)\n",
    "print(\"solution V = \", sol1)\n",
    "print(\"L V = \", np.matmul(L, sol1), \"  b = \", b1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7af57e9b",
   "metadata": {},
   "source": [
    "**Question 1.2.**\n",
    "\n",
    "Write down the steps of the Cholesky algorithm to decompose the matrix $B = L L^T$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ea15da5",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n",
    "We apply the Cholesky algorithm with the following algorithms:\n",
    "\n",
    "- Iterations: For $i$ from 1 to $N$ (here N is 3)\n",
    "\n",
    "  - We first compute values in diagonal\n",
    "  $$\n",
    "  L_{i,i} = \\sqrt{B_{i,i}-\\sum_{k=1}^{i-1}L_{i,k}^2}\n",
    "  $$\n",
    "\n",
    "  - Then, for i from i to N, we have\n",
    "  $$\n",
    "  L_{i,j} = \\frac{B_{i,j}-\\sum_{k=1}^{j-1}L_{i,k}L_{j,k}}{L_{j,j}}, \\quad \\text{for } i>j\n",
    "  $$\n",
    "\n",
    "However, for the above algorithms, in order to compute the diagonal, we need to know the values in the column, so more precisely, we need to compute $L$ **column by column from left to right**, we start from the first column.\n",
    "\n",
    "- We first compute the first diagonal point in the first column with formula:\n",
    "  $$\n",
    "  L_{1,1} = \\sqrt{B_{1,1}}\n",
    "  $$\n",
    "  Then we can compute the rest points in the first column\n",
    "  $$\n",
    "  L_{i,1} = \\frac{B_{i,1}}{L_{1,1}}, \\quad \\text{for } i>1\n",
    "  $$\n",
    "\n",
    "- For the second column, we also **first compute the diagonal point** in the columns with the formula we have above, then we compute the rest points in the columns.\n",
    "\n",
    "- We apply the similar algorithms for the third column and rest columns.\n",
    "\n",
    "Therefore, we have the following program to solve the problem $B = L L^T$, we have the final result:\n",
    "$$\n",
    "L = \\begin{pmatrix} 1 & 0 & 0 \\\\ 2 & 1 & 0 \\\\ 1 & 2 & 1 \\end{pmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eccd46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cholesky_decomp(B):\n",
    "    N = len(B[0, :])\n",
    "    L = np.eye(N)\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(i):\n",
    "            L[i, j] = (B[i, j] - np.sum([L[i, k] * L[j, k]\n",
    "                                         for k in range(j)])) / L[j, j]\n",
    "        L[i,\n",
    "          i] = np.sqrt(B[i, i] - np.sum([L[i, k] * L[i, k] for k in range(i)]))\n",
    "\n",
    "    return L\n",
    "\n",
    "\n",
    "# result\n",
    "B = np.array([[1, 2, 1], [2, 5, 4], [1, 4, 6]])\n",
    "# implement your test here\n",
    "\n",
    "print(\"Matrix:\\n\", B, \"\\n\")\n",
    "print(\"Cholesky decomposition:\\n\", Cholesky_decomp(B))\n",
    "L = Cholesky_decomp(B)\n",
    "print(\"L L^T =\\n \", np.matmul(L, np.transpose(L)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc42034",
   "metadata": {},
   "source": [
    "## Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-producer",
   "metadata": {},
   "source": [
    "**Definition:** A matrix $S$ is orthogonal if it is invertible and its inverse satisfies $S^{-1} = S^T$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-voluntary",
   "metadata": {},
   "source": [
    "The goal of this tutorial is to construct an algorithm providing a decomposition of a matrix $A = S U$ into the product of an orthogonal matrix $S$ and an upper triangular one $U$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-dryer",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preliminary computations on orthogonal matrices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "greater-booth",
   "metadata": {},
   "source": [
    "**Question 2.1.**\n",
    "\n",
    "a) Consider an orthogonal matrix $S$. What values can $det(S)$ have?\n",
    "\n",
    "b) Are all matrices satisfying this property orthogonal? Prove it or give a counterexample. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "brown-chemical",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "a) We have the definition of orthogonal matrix $S$ is that $S^{-1} = S^T$. Also we know that $det(S^{-1}) = \\frac{1}{det(S)}$. Therefore, we have the equation that\n",
    "  $$\n",
    "  det(S^{-1}) = det(S^T) \\Rightarrow det(S) = \\frac{1}{det(S)} \\Rightarrow det(S)^2 = 1\n",
    "  $$\n",
    "  Therefore, we have $det(S) = \\pm 1$\n",
    "\n",
    "b) We have the matrix $A = \\begin{pmatrix} 1 & 0 \\\\ 2 & 1 \\end{pmatrix}$, where $det(A)=1$. However, we have $A^{-1}= \\begin{pmatrix} 1 & 0 \\\\ -2 & 1 \\end{pmatrix} \\neq  \\begin{pmatrix} 1 & 2 \\\\ 0 & 1 \\end{pmatrix}=A^{T}$. Therefore, we have the counterexample that not all matrices satisfying the property of orthogonal matrix $S$ are orthogonal.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "possible-vertical",
   "metadata": {},
   "source": [
    "**Question 2.2.**\n",
    "\n",
    "Prove that the product of orthogonal matrices remains an orthogonal matrix. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "controversial-accommodation",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We assume that matrix $A \\in \\mathbb{R}^{N \\times N}$ and $B \\in \\mathbb{R}^{N \\times N}$ are orthogonal matrices. Then obviously $A$ and $B$ are invertible. We also have the property that $A^{T}=A^{-1}$ and $B^{T}=B^{-1}$. We have the following equation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(AB)^{T} &= B^{T} A^T \\\\\n",
    "&= B^{-1} A^{-1} \\\\\n",
    "&= (AB)^{-1}\n",
    "\\end{aligned}\n",
    "$$\n",
    "For the property $AB^{-1} = B^{-1}A^{-1}$, we have following proof: By the definition of inverse matrix:\n",
    "$$\n",
    "\\mathbf{A} \\mathbf{A}^{-1}=\\mathbf{A}^{-1} \\mathbf{A}=\\mathbf{I}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\mathbf{B B}^{-1}=\\mathbf{B}^{-1} \\mathbf{B}=\\mathbf{I}\n",
    "$$\n",
    "Now, observe that:\n",
    "$$\n",
    "\\begin{array}{rlr}\n",
    "(\\mathbf{A B})\\left(\\mathbf{B}^{-1} \\mathbf{A}^{-1}\\right) & =\\left(\\mathbf{A}\\left(\\mathbf{B} \\mathbf{B}^{-1}\\right)\\right) \\mathbf{A}^{-1} & \\text { (Matrix Multiplication is Associative) } \\\\\n",
    "& =(\\mathbf{A I}) \\mathbf{A}^{-1} & \\\\\n",
    "& =\\mathbf{A} \\mathbf{A}^{-1} & \\\\\n",
    "& =\\mathbf{I} & \\text { (Definition of Identity Element) }\n",
    "\\end{array}\n",
    "$$\n",
    "Similarly:\n",
    "$$\n",
    "\\begin{array}{rlr}\n",
    "\\left(\\mathbf{B}^{-1} \\mathbf{A}^{-1}\\right)(\\mathbf{A B}) & =\\left(\\mathbf{B}^{-1}\\left(\\mathbf{A}^{-1} \\mathbf{A}\\right)\\right) \\mathbf{B} \\quad \\text { (Matrix Multiplication is Associative) } \\\\\n",
    "& =\\left(\\mathbf{B}^{-1} \\mathbf{I}\\right) \\mathbf{B} & \\\\\n",
    "& =\\mathbf{B}^{-1} \\mathbf{B} \\quad \\text { (Definition of Identity Element) } \\\\\n",
    "& =\\mathbf{I}\n",
    "\\end{array}\n",
    "$$\n",
    "Then we prove the property that the product of orthogonal matrices remains an orthogonal matrix.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "outdoor-spyware",
   "metadata": {},
   "source": [
    "**Question 2.3.**\n",
    "\n",
    "Prove that the Euclidean norm of a vector is preserved when multiplying it by an orthogonal matrix $S$, i.e. \n",
    "\n",
    "$$\\|S V\\| = \\|V\\|$$\n",
    "\n",
    "where the Euclidean norm yields $\\|V\\| = \\sqrt{V^T V}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "sound-moderator",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\|SV\\| &= \\|(SV)^{T}SV\\| \\\\\n",
    "&= \\|V^{T}S^{T}SV\\| \\\\\n",
    "&= \\|V^{T}S^{-1}SV\\|\\quad \\text{Since $S$ is orthogonal matrix} \\\\\n",
    "&= \\|V^{T}V\\| \\\\\n",
    "&= \\|V\\|\n",
    "\\end{aligned}\n",
    "$$\n",
    "Then we finish the proof.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "rolled-bahrain",
   "metadata": {},
   "source": [
    "**Question 2.4.**\n",
    "\n",
    "Consider a vector $V \\in \\mathbb{R}^N$, and define the matrix \n",
    "\n",
    "$$ S(V) = Id - 2 \\frac{V V^T}{\\|V\\|^2},$$ \n",
    "\n",
    "where $\\|V\\| = \\sqrt{V^T V}$ denotes the Euclidean norm of $V$. \n",
    "\n",
    "Prove that $S(V)$ is an orthogonal matrix. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "broken-polymer",
   "metadata": {},
   "source": [
    "**Answer:**  \n",
    "\n",
    "- We first prove that $S(V)$ is square, since $V \\in \\mathbb{R}^{N}$, therefore we have $VV^{T} \\in \\mathbb{R}^{N, N}$. Then we have $S(V) \\in \\mathbb{R}^{N, N}$ is square.\n",
    "\n",
    "- Then we try to prove $S(V)S(V)^{T}=I$. We have for $S(V)^{T}$:\n",
    "  $$\n",
    "  S(V)^{T} = Id^{T} - 2 \\frac{(V^{T} V)^{T}}{\\|V\\|^2} = Id - 2 \\frac{(V^{T})^{T} V^{T}}{\\|V\\|^2} = Id - 2 \\frac{V V^T}{\\|V\\|^2} = S(V)\n",
    "  $$\n",
    "  Then we can compute $S(V)S(V)^{T}$:\n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  S(V)S(V)^{T} & = S(V)^2 \\\\\n",
    "  &= (Id - 2 \\frac{V V^T}{\\|V\\|^2})^2 \\\\\n",
    "  &= Id - 4 \\frac{V V^T}{\\|V\\|^2} + 4 \\frac{(V V^T)^{2}}{\\|V\\|^4} \\\\\n",
    "  &= Id - 4 \\frac{V V^T}{\\|V\\|^2} + 4 \\frac{V V^T V V^T}{\\|V\\|^4} \\\\\n",
    "  &= Id - 4 \\frac{V V^T}{\\|V\\|^2} + 4 \\frac{ \\|V\\|^2 V V^T}{\\|V\\|^4} \\\\\n",
    "  &= Id - 4 \\frac{V V^T}{\\|V\\|^2} + 4 \\frac{V V^T}{\\|V\\|^2} \\\\\n",
    "  &= Id\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "\n",
    "- Finally, we need to prove that $S(V)$ is invertible, we can prove this by computing its determinant\n",
    "  $$\n",
    "  det(S(V)) = det(Id - 2 \\frac{V V^T}{\\|V\\|^2}) =  1 - 2 \\frac{V^T V}{\\|V\\|^2} = 1 - 2 \\frac{\\|V\\|^2}{\\|V\\|^2} =  -1 \\neq 0\n",
    "  $$\n",
    "  Then we prove that $S(V)$ is invertible.\n",
    "\n",
    "Therefore, we prove that $S(V)$ is an orthogonal matrix."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "diverse-guitar",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Construction of the algorithm (QR decomposition based on Householder reflections)\n",
    "\n",
    "As in the Gaussian elimination algorithm, we eliminate the subdiagonal coefficients of a matrix $A$. But, instead of using elementary matrices, we use orthogonal matrices $S(V)$ as defined in 4).  \n",
    "\n",
    "Let us rewrite $A = (C^1, C^2, \\dots, C^N)$ as a row vector of column vectors $C^i \\in \\mathbb{R}^N$. We multiply iteratively the matrix $A$, and therefore each of its column, by an orthogonal matrix $S(V^i)$.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "threatened-direction",
   "metadata": {},
   "source": [
    "**Question 2.5.**\n",
    "\n",
    "Consider $C^1 \\in \\mathbb{R}^N$, we seek a vector $V^1 \\in \\mathbb{R}^N$ such that \n",
    "\n",
    "$$S(V^1) C^1 = \\left( \\begin{array}{c} \\alpha \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{array} \\right). \\qquad{} (1) $$ \n",
    "\n",
    "What are the possible values of $\\alpha$? If there are several possibilities, choose one of them here for the rest of the algorithm. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58d82b78",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We assume the equation \n",
    "$$S(V^1) C^1 = \\left( \\begin{array}{c} \\alpha \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{array} \\right)$$ \n",
    "Therefore, we have the following equation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "S(V^1) C^1 &= \\begin{pmatrix} \\alpha \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}   \\\\\n",
    "(Id - 2 \\frac{V^{1}(V^{1})^{T}}{\\|V^{1}\\|^2}) C^{1} &= \\alpha e_{1} \\\\\n",
    "2\\frac{(C^{1})^{T}V^{1}}{\\|V^{1}\\|^2} V^{1} &= C^{1} - \\alpha e_{1} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Since we know that $2\\frac{(C^{1})^{T}V^{1}}{\\|V^{1}\\|^2}$ is a constant, we can rewrite the equation as:\n",
    "$$\n",
    "V^{1} = m(C^{1} - \\alpha e_{1}) \\quad \\text{where $m$ is a constant}\n",
    "$$h\n",
    "In order to apply the elimination, we have $\\alpha = \\pm \\|C^1\\|_{2}$ and $V = m(C^1 \\pm \\|C^1\\|_{2}e_{1})$ where $m$ is any constant and **we choose** $\\alpha = \\|C^1\\|_{2}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1faac9f",
   "metadata": {},
   "source": [
    "**Question 2.6.**\n",
    "\n",
    "We seek $V^1\\in\\mathbb{R}^N$ satisfying (1) and such that $\\|V^1\\| = 1$. Let us decompose $V^1 = \\left( \\begin{array}{c} a \\\\ W \\end{array} \\right)$ and $C^1 = \\left( \\begin{array}{c} b \\\\ X \\end{array} \\right)$.\n",
    "\n",
    "a) Prove that $W = kX$ is proportional to $X$. \n",
    "\n",
    "b) Write $a$ as a function of $k$ and $X$.\n",
    "\n",
    "c) Write an equation satisfied by $k$ depending only on $X$ and $b$. \n",
    "\n",
    "d) Solve this equation and compute $k$.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4734e7a",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "a) From previous question, we choose $\\alpha=\\|C^1\\|_{2}$. Therefore, we have the following equation:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "(Id-2(V^{1})^{T}V^{1}) C^{1} &= \\|C^1\\|_{2} e_{1} \\\\\n",
    "C^{1} - 2 (V^{1})^{T}V^{1} C^{1} &= \\|C^1\\|_{2} e_{1}\\\\\n",
    "C^{1} - 2 ((C^{1})^{T} V^{1})V^{1} &= \\|C^1\\|_{2} e_{1}\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "Since $(C^{1})^{T} V$ is a constant, we can rewrite the equation as:\n",
    "$$\n",
    "V^{1} = m(C^{1} - \\|C^1\\|_{2} e_{1}) \\quad \\text{where $m$ is a constant}\n",
    "$$\n",
    "Therefore we have the relation that\n",
    "$$\n",
    "\\begin{pmatrix} a \\\\ W \\end{pmatrix} = m \\begin{pmatrix} b-\\|C^1\\|_{2} \\\\ X \\end{pmatrix} \n",
    "$$\n",
    "Therefore, here $m$ is $k$, we prove that $W = kX$ is proportional to $X$.\n",
    "\n",
    "b) Since we have $\\|V^{1}\\|=1$, therefore, we have\n",
    "$$\n",
    "\\|V^{1}\\|^2 = a^{2}+\\|W\\|^2 =1\n",
    "$$\n",
    "Also, from the previous equation, we have\n",
    "$$\n",
    "W = kX \\Rightarrow a^{2}+k^{2}\\|X\\|^2 =1 \n",
    "$$\n",
    "Therefore, we can deduce that\n",
    "$$\n",
    "a^{2} = 1-k^{2}\\|X\\|^2 \\Rightarrow a = \\sqrt{1-k^{2}\\|X\\|^2}\n",
    "$$\n",
    "\n",
    "c) From previous equation, we have\n",
    "$$\n",
    "\\begin{cases}\n",
    "a = k(b-\\|C^1\\|_{2})\\\\\n",
    "W = kX\n",
    "\\end{cases}\n",
    "$$\n",
    "For the first equation, we got\n",
    "$$\n",
    "a = k(b-\\sqrt{b^{2}+\\|X\\|^{2}}) \\Rightarrow \\sqrt{1-k^{2}\\|X\\|^2} = k(b-\\sqrt{b^{2}+\\|X\\|^{2}})\n",
    "$$\n",
    "Therefore, by take the square on both side, we have:\n",
    "$$\n",
    "1-k^{2}\\|X\\|^2 = k^{2}(b-\\sqrt{b^{2}+\\|X\\|^{2}})^{2}\n",
    "$$\n",
    "\n",
    "d) From the equation in c), we have:\n",
    "$$\n",
    "1 = k^{2} (\\|X\\|^2 + (b-\\sqrt{b^{2}+\\|X\\|^{2}})^{2}) \\Rightarrow k = \\frac{1}{\\sqrt{\\|X\\|^2 + (b-\\sqrt{b^{2}+\\|X\\|^{2}})^{2}}}\n",
    "$$\n",
    "We can represent $k$ with $X$ and $b$:\n",
    "$$\n",
    "k = \\frac{1}{\\sqrt{\\|X\\|^2 + (b-\\sqrt{b^{2}+\\|X\\|^{2}})^{2}}}\n",
    "$$\n",
    "**Or we can express $k$ with $\\alpha$, we have**:\n",
    "$$\n",
    "k = \\frac{1}{\\sqrt{\\|X\\|^2 + (b-\\sqrt{b^{2}+\\|X\\|^{2}})^{2}}} = \\frac{1}{\\sqrt{\\|X\\|^2+b^{2}-2b\\sqrt{b^{2}+\\|X\\|^{2}}+\\|X\\|^2}+b^2} = \\frac{1}{\\sqrt{2(b^2+\\|X\\|^2)-2b\\sqrt{b^2+\\|X\\|^2}}}\n",
    "$$\n",
    "Therefore, we subsitute $\\alpha$ with $\\sqrt{b^2+\\|X\\|^2}$:\n",
    "$$\n",
    "k = \\frac{1}{\\sqrt{2 \\alpha (\\alpha - b)}}\n",
    "$$\n",
    "Where $\\alpha = \\sqrt{b^2 + \\|X\\|^2}$. **Both expressions of $k$ with $k=\\frac{1}{\\sqrt{\\|X\\|^2 + (b-\\sqrt{b^{2}+\\|X\\|^{2}})^{2}}}$ and $k = \\frac{1}{\\sqrt{2 \\alpha (\\alpha - b)}}$ with $\\alpha = \\sqrt{b^2 + \\|X\\|^2}$ should be the same**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "196acc27",
   "metadata": {},
   "source": [
    "**Question 2.7.**\n",
    "\n",
    "a) What vector operations do you need to perform to compute $S(V^1) C^2$ for some other vector $C^2 \\in\\mathbb{R}^N$? \n",
    "\n",
    "b) How many scalar operations are therefore necessary to compute this product?\n",
    "\n",
    "c) How many scalar operations are therefore necessary to compute the product $S(V^1) A$, without performing the trivial operations?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48e0fc4c",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "a) From the previous formola, we got \n",
    "$$\n",
    "S(V^1) C^2 = (Id - 2 \\frac{V^{1}(V^{1})^{T}}{\\|V\\|^2}) C^{2} \n",
    "$$\n",
    "Since we already know that $\\|V^{1}\\|=1$. Therefore, we have \n",
    "$$\n",
    "\\begin{aligned}\n",
    "S(V^1) C^2 &= (Id - 2 \\frac{V^{1}(V^{1})^{T}}{\\|V\\|^2}) C^{2} \\\\\n",
    "&=  (Id - 2 V^{1}(V^{1})^{T})C^{2} \\\\\n",
    "&= C^{2} - 2 V^{1}(V^{1})^{T} C^{2} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Therefore, we have **4 vector operations** in total, which are:\n",
    "- 1 vector transpose: $(V^{1})^{T}$\n",
    "- 2 vector multiplication: $V^{1}(V^{1})^{T}$ and multiplication between $V^{1}(V^{1})^{T}$ and $C^{2}$\n",
    "- 1 vector subtraction: $C^{2} - 2 V^{1}(V^{1})^{T} C^{2}$\n",
    "\n",
    "Since $\\|V^1\\|^2$ is a constant, the division operation is not vector operation. Therefore, we have **4 vector operations** in total.\n",
    "\n",
    "\n",
    "b) Since we have:\n",
    "$$\n",
    "S(V^1) C^2 = C^{2} - 2 V^{1}(V^{1})^{T} C^{2}\n",
    "$$\n",
    "\n",
    "Therefore, we have **n scalar operations** in total, which is:\n",
    "- n scalar multiplication: since we know that $V^{1}(V^{1})^{T} C^{2} \\in \\mathbb{R}^n$, therefore, we have **n scalar multiplication**.\n",
    "\n",
    "c) Since $A = (C^1, C^2, \\cdots, C^n)$ is a matrix containing $n$ vectors, therefore, we have:\n",
    "$$\n",
    "n \\times n \\text{ scalar operation} = n^2 \\text{ scalar operations}\n",
    "$$\n",
    "Therefore, for each vector $C^i$, we need to perform **n scalar operation**. Therefore, we have **$n^{2}$ scalar operations** in total."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1284ec57",
   "metadata": {},
   "source": [
    "**Question 2.8.**\n",
    "\n",
    "Now, we need to eliminate the subdiagonal term on the second column without modifying the first column of $A^1 := S(V^1)A$, i.e. we want \n",
    "\n",
    "$$S(V^2) \\tilde{C}^2 = \\left( \\begin{array}{c} * \\\\ \\beta \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{array} \\right).$$\n",
    "\n",
    "where $\\tilde{C}^i$ is the i-th column of $A^1$.\n",
    "\n",
    "For this purpose, we use another matrix $S(V^2)$ satisfying \n",
    "\n",
    "$$ S(V^2)_{1,i} = \\delta_{1,i}. $$\n",
    "\n",
    "What does this condition imposes on the entries of the vector $V^2$ ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "201b0eb8",
   "metadata": {},
   "source": [
    "**Answer (Description of the algorithms):** \n",
    "After the decomposition with $S(V^1)C^1$, we got:\n",
    "$$\n",
    "A^{1}=S(V^1) A=\\left[\\begin{array}{c|ccc}\n",
    "\\alpha & \\tilde{a}_{12} & \\cdots & \\tilde{a}_{1 n} \\\\\n",
    "\\hline 0 & & & \\\\\n",
    "\\vdots & & \\tilde{A}_2 & \\\\\n",
    "0 & & &\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "Then we try to eliminate the subdiagonal term on the second column without modifying the first column of $A^1 := S(V^1)A$, we can apply the same method to the $\\tilde{A}_2 \\in \\mathbb{R}^{(n-1) \\times (n-1)}$. We try to find a householder matrix $\\tilde{H}_2 \\in \\mathbb{R}^{(n-1) \\times (n-1)}$ to elminate all the numbers in the first column of $\\tilde{A}_2$ to 0 as follow:\n",
    "$$\n",
    "\\tilde{H}_2 \\tilde{A}_2=\\left[\\begin{array}{c|ccc}\n",
    "\\beta & \\tilde{a}_{23} & \\cdots & \\tilde{a}_{2 n} \\\\\n",
    "\\hline 0 & & & \\\\\n",
    "\\vdots & & \\tilde{A}_3 & \\\\\n",
    "0 & & &\n",
    "\\end{array}\\right] .\n",
    "$$\n",
    "where we got\n",
    "$$\n",
    "S(V^2) =\\left[\\begin{array}{cc}\n",
    "1 & 0 \\\\\n",
    "0 & \\tilde{H}_2\n",
    "\\end{array}\\right] \\text {. }\n",
    "$$\n",
    "where $S(V^2) \\in \\mathbb{R}^{n \\times n}$ and we have \n",
    "$$\n",
    "S(V^2) S(V^1) A=\\left[\\begin{array}{c|ccc}\n",
    "\\alpha & \\tilde{a}_{12} & \\cdots & \\tilde{a}_{1 n} \\\\\n",
    "\\hline 0 & & & \\\\\n",
    "\\vdots & & \\tilde{H}_2 \\tilde{A}_2 & \\\\\n",
    "0 & & &\n",
    "\\end{array}\\right]=\\left[\\begin{array}{cc|ccc}\n",
    "\\alpha & \\tilde{a}_{12} & \\tilde{a}_{13} & \\cdots & \\tilde{a}_{1 n} \\\\\n",
    "0 & \\beta & \\tilde{a}_{23} & \\cdots & \\tilde{a}_{2 n} \\\\\n",
    "\\hline 0 & 0 & & & \\\\\n",
    "\\vdots & \\vdots & & \\tilde{A}_3 & \\\\\n",
    "0 & 0 & & &\n",
    "\\end{array}\\right] .\n",
    "$$\n",
    "And the algorithm is applied interatively in this way.\n",
    "\n",
    "---\n",
    "\n",
    "**Answer to the Question 2.8:**\n",
    "\n",
    "Since $S(V^2)$ is a orthogonal matrix, we have $S(V^2)_{1,i} = \\delta_{1,i}$ and $S(V^2)_{i,1} = \\delta_{1,i}$. Therefore, the matrix $S(V^2)$ should be in this format:\n",
    "$$\n",
    "S(V^2) =\\left[\\begin{array}{cc}\n",
    "1 & 0 \\\\\n",
    "0 & \\tilde{H}_2\n",
    "\\end{array}\\right]\n",
    "$$\n",
    "We also have: \n",
    "$$\n",
    "S(V^2) \\tilde{C}^2 = \\left( \\begin{array}{c} * \\\\ \\beta \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{array} \\right).\n",
    "$$\n",
    "Therefore, we need to find a vector $V^2 \\in \\mathbb{R}^N$ such that $S(V^2) =\\left[\\begin{array}{cc}\n",
    "1 & 0 \\\\\n",
    "0 & \\tilde{H}_2\n",
    "\\end{array}\\right]$. From the previous formola, we got:\n",
    "$$\n",
    "S(V^2) = (Id - 2 \\frac{V^{2}(V^{2})^{T}}{\\|V\\|^2}) = \\left[\\begin{array}{cc}\n",
    "1 & 0 \\\\\n",
    "0 & \\tilde{H}_2\n",
    "\\end{array}\\right]\n",
    "$$. \n",
    "Therefore, in order to make $S(V^2)_{1,1}=1=Id_{1,1}$, we got $V^2=\\begin{pmatrix}0 \\\\ v_2 \\\\ \\vdots \\\\ v_n \\end{pmatrix}$. Next, we try to compute the part of $V^2$ for $v_2$ to $v_n$. This question is equivalent to how can we decompose to $\\tilde{H}_2$ such that $\n",
    "\\tilde{H}_2 \\tilde{A}_2=\\left[\\begin{array}{c|ccc}\n",
    "\\beta & \\tilde{a}_{23} & \\cdots & \\tilde{a}_{2 n} \\\\\n",
    "\\hline 0 & & & \\\\\n",
    "\\vdots & & \\tilde{A}_3 & \\\\\n",
    "0 & & &\n",
    "\\end{array}\\right] \n",
    "$. We can see that this problem is the exactly same with the **Question 2.6**. Therefore, we can use the same method to solve this problem.\n",
    "\n",
    "We denote a vector $V' \\in \\mathbb{R}^{n-1} = \\begin{pmatrix} v_2 \\\\ \\vdots \\\\ v_n \\end{pmatrix}$. From **Question 2.5**, we have the formula for $V'$ such that\n",
    "$$\n",
    "V' = \\tilde{C}^2_{sub}- \\|\\tilde{C}^2_{sub}\\|_{2} e_{1}\n",
    "$$\n",
    "where we denote $\\tilde{C}^2_{sub} = \\begin{pmatrix} \\tilde{a}_{22} \\\\ \\vdots \\\\ \\tilde{a}_{n 2} \\end{pmatrix}$ and $e_1 ' \\in \\mathbb{R}^{n-1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ \\vdots\\\\ 0 \\end{pmatrix}$. Therefore, we can conclude that \n",
    "$$\n",
    "V^2 = \\begin{pmatrix} 0 \\\\ V' \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\tilde{a}_{22} - \\|\\tilde{C}^2_{sub}\\|_{2} \\\\ \\tilde{a}_{32} \\\\ \\vdots \\\\ \\tilde{a}_{n2}  \\end{pmatrix}\n",
    "$$\n",
    "where $\\tilde{C}^2_{sub} = \\begin{pmatrix} \\tilde{a}_{22} \\\\ \\vdots \\\\ \\tilde{a}_{n 2} \\end{pmatrix}$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff5aa670",
   "metadata": {},
   "source": [
    "**Question 2.9.**\n",
    "\n",
    "Again, what is the value of $\\beta$ ? And propose a vector $V^2 \\in \\mathbb{R}^N$ satisfying $\\|V^2\\| = 1$ and (2).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5971af3f",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "From the conclusion of **Question 2.5** and the algorithms of **Question 2.8**, we choose $\\alpha = \\|C^1\\|$, for the same reason, we choose $\\beta = \\|\\tilde{C}^2_{sub}\\|$. Therefore, we have:\n",
    "$$\n",
    "\\beta = \\|\\tilde{C}^2_{sub}\\| = \\sqrt{\\tilde{a_{22}}^2 + \\cdots  +\\tilde{a_{n2}}^2} = \\sqrt{\\|\\tilde{C}^2\\|-\\tilde{a_{12}}^2}\n",
    "$$\n",
    "where **$\\tilde{a_{22}}, \\cdots, \\tilde{a_{n2}}$ are from $\\tilde{C}^2 = \\text{i-th column of }A^{1} = \\begin{pmatrix} \\tilde{a}_{12} \\\\ \\tilde{a}_{22} \\\\ \\vdots \\\\ \\tilde{a}_{n 2} \\end{pmatrix}$** \n",
    "\n",
    "---\n",
    "\n",
    "In order to satisfy $\\|V^2\\| = 1$, we set \n",
    "$$\n",
    "A^{1} = \\begin{pmatrix} \\tilde{a}_{12} \\\\ \\tilde{a}_{22} \\\\ X' \\end{pmatrix} \\quad \\text{and} \\quad V^{2} = \\begin{pmatrix} 0 \\\\ a' \\\\ W' \\end{pmatrix}\n",
    "$$\n",
    "We apply the same algorithm as **Question 2.6** to compute $V^{2}$. We have:\n",
    "$$\n",
    "b' = \\tilde{a}_{22}\n",
    "$$\n",
    "From **Question 2.6 d)**, we have:\n",
    "$$\n",
    "k' = \\frac{1}{2\\beta (\\beta - \\tilde{a}_{22})} \n",
    "$$\n",
    "Then we got\n",
    "$$\n",
    "a' = \\sqrt{1-(k')^2 \\|X'\\|^2}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "W' = k' X'\n",
    "$$\n",
    "In conclusion, we got the vector of $V^{2}$:\n",
    "$$\n",
    "V^{2} =  \\begin{pmatrix} 0 \\\\ \\sqrt{1-(k')^2  \\|X'\\|^2} \\\\  k' X' = k' \\begin{pmatrix} \\tilde{a}_{32} \\\\ \\vdots \\\\ \\tilde{a}_{n2} \\end{pmatrix} \\end{pmatrix}\n",
    "$$\n",
    "where $X' = \\begin{pmatrix} \\tilde{a}_{32} \\\\ \\vdots \\\\ \\tilde{a}_{n2} \\end{pmatrix}$, $k' = \\frac{1}{2\\beta (\\beta - \\tilde{a}_{22})}$ and $\\beta = \\|\\tilde{C}^2_{sub}\\| = \\sqrt{\\tilde{a_{22}}^2 + \\cdots  +\\tilde{a_{n2}}^2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6dd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "def qr_householder(A):\n",
    "    m, n = A.shape\n",
    "    Q = np.eye(m)\n",
    "    R = A.copy()\n",
    "\n",
    "    for j in range(n):\n",
    "        # Apply Householder transformation to eliminate below-diagonal entries\n",
    "        x = R[j:, j]\n",
    "        norm_x = np.linalg.norm(x)\n",
    "        v = np.zeros_like(x)\n",
    "        v[0] = np.copysign(norm_x, x[0])\n",
    "        v += x\n",
    "        v /= np.linalg.norm(v)\n",
    "\n",
    "        R[j:, :] -= 2 * np.outer(v, np.dot(v, R[j:, :]))\n",
    "        Q[:, j:] -= 2 * np.outer(Q[:, j:], np.dot(Q[:, j:].T, v))\n",
    "\n",
    "    return Q.T, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425d3fc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In practice, this technique is applied iteratively to all columns until writing a product of the form \n",
    "\n",
    "$$\\left(\\prod\\limits_i S(V^i) \\right) A = U $$\n",
    "\n",
    "which provides the decomposition $A = SU$ where $S = \\left(\\prod\\limits_i S(V^i) \\right)^T$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
